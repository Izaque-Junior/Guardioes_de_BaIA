{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7883e7fe-8d8f-45ac-818a-14181233599a",
   "metadata": {},
   "source": [
    "# Atividade Final: Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a295c27-e71f-4dc9-a55d-2ab2cbeab1b7",
   "metadata": {},
   "source": [
    "O Grande Rei de Lumi convocou uma reunião do Conselho Real a fim de discutir o futuro da saúde pública de seu reino. Diana Didatolov, que estava presente, mostrou os dados coletados pela Organização Mística da Saúde (OMS) e arquivados na Biblioteca Real, os quais continham informações preciosas a respeito da saúde pública das várias regiões de Lumi nos últimos anos. O rei, que se preocupava muito com a qualidade de vida de seus anciãos, desejava prever a futura expectativa de vida das diversas regiões do reino. O que Diana não sabia, no entanto, era como obter tal informação a partir de uma coleção de dados tão extensa.\n",
    "\n",
    "Diante desse problema, o Grande Rei convocou a guilda mais poderosa de Lumi, composta por dois bravos cavaleiros e duas magas poderosas: Os Guardiões de Ba'IA. \n",
    "\n",
    "Os Cavaleiros Maria e Izaque, que possuem muitos contatos através do reino, decidiram perguntar aos sábios do Clã Vizin'Hos qual seria a solução do problema.\n",
    "\n",
    "A Maga Dara, por outro lado, achou mais sábio perguntar à grande Árvore do Conhecimento a resposta.\n",
    "\n",
    "Já a Feiticeira Alice, não satisfeita, viajou até a Floresta da Elucidação em busca de uma maneira de ajudar o Rei. \n",
    "\n",
    "Alice, Izaque, Maria e Dara retornaram com respostas diferentes a respeito da expectativa de vida de cada região. Mas como saber qual desses métodos se aproximou mais da realidade? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b63e47a-4643-4ab6-8d14-f224d573f892",
   "metadata": {},
   "source": [
    "Descrição do Projeto:\n",
    "Comparar diversos modelos de previsão (KNN-vizinhos, Árvore de Decisão e Floresta de Decisão) e métodos de tratamento de dados quanto a sua eficiência na predição. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bab0d98-361f-45be-ae3d-2bab1fc29816",
   "metadata": {},
   "source": [
    "Iniciamos importando todas as bibliotecas e métodos que serão utilizadas para a atividade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78071a39-0def-43a2-9414-d48f9f4da5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics as st\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36077964-fe1f-4886-b393-98b7b33ca23a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tratamento de Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ffaa64-4c2f-4609-8c56-16f820532a78",
   "metadata": {},
   "source": [
    "O primeiro passo para a realização da atividade é o tratamento dos dados do nosso DataFrame. Ao longo desse tratamento, criaremos diferentes versões do data frame e, ao final, usaremos cada um deles para treinar diferentes modelos. Por fim, iremos avaliar e comparar a eficiência de cada um desses modelos na predição. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09b24ff-2bde-426d-862a-6a19ca39bdf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Primeiros Passos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7306674c-2c5d-467d-bc19-e9256679469e",
   "metadata": {},
   "source": [
    "Primeiro vamos salvar nosso dataframe numa variável, assim como obter algumas informações básicas sobre ele, como número de linhas e colunas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9b6e75-b00a-43cb-a386-e4a42a7e7a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Country  Year      Status  Life expectancy   Adult Mortality  \\\n",
      "0     Afghanistan  2015  Developing              65.0            263.0   \n",
      "1     Afghanistan  2014  Developing              59.9            271.0   \n",
      "2     Afghanistan  2013  Developing              59.9            268.0   \n",
      "3     Afghanistan  2012  Developing              59.5            272.0   \n",
      "4     Afghanistan  2011  Developing              59.2            275.0   \n",
      "...           ...   ...         ...               ...              ...   \n",
      "2933     Zimbabwe  2004  Developing              44.3            723.0   \n",
      "2934     Zimbabwe  2003  Developing              44.5            715.0   \n",
      "2935     Zimbabwe  2002  Developing              44.8             73.0   \n",
      "2936     Zimbabwe  2001  Developing              45.3            686.0   \n",
      "2937     Zimbabwe  2000  Developing              46.0            665.0   \n",
      "\n",
      "      infant deaths  Alcohol  percentage expenditure  Hepatitis B  Measles   \\\n",
      "0                62     0.01               71.279624         65.0      1154   \n",
      "1                64     0.01               73.523582         62.0       492   \n",
      "2                66     0.01               73.219243         64.0       430   \n",
      "3                69     0.01               78.184215         67.0      2787   \n",
      "4                71     0.01                7.097109         68.0      3013   \n",
      "...             ...      ...                     ...          ...       ...   \n",
      "2933             27     4.36                0.000000         68.0        31   \n",
      "2934             26     4.06                0.000000          7.0       998   \n",
      "2935             25     4.43                0.000000         73.0       304   \n",
      "2936             25     1.72                0.000000         76.0       529   \n",
      "2937             24     1.68                0.000000         79.0      1483   \n",
      "\n",
      "      ...  Polio  Total expenditure  Diphtheria    HIV/AIDS         GDP  \\\n",
      "0     ...    6.0               8.16         65.0        0.1  584.259210   \n",
      "1     ...   58.0               8.18         62.0        0.1  612.696514   \n",
      "2     ...   62.0               8.13         64.0        0.1  631.744976   \n",
      "3     ...   67.0               8.52         67.0        0.1  669.959000   \n",
      "4     ...   68.0               7.87         68.0        0.1   63.537231   \n",
      "...   ...    ...                ...          ...        ...         ...   \n",
      "2933  ...   67.0               7.13         65.0       33.6  454.366654   \n",
      "2934  ...    7.0               6.52         68.0       36.7  453.351155   \n",
      "2935  ...   73.0               6.53         71.0       39.8   57.348340   \n",
      "2936  ...   76.0               6.16         75.0       42.1  548.587312   \n",
      "2937  ...   78.0               7.10         78.0       43.5  547.358878   \n",
      "\n",
      "      Population   thinness  1-19 years   thinness 5-9 years  \\\n",
      "0     33736494.0                   17.2                 17.3   \n",
      "1       327582.0                   17.5                 17.5   \n",
      "2     31731688.0                   17.7                 17.7   \n",
      "3      3696958.0                   17.9                 18.0   \n",
      "4      2978599.0                   18.2                 18.2   \n",
      "...          ...                    ...                  ...   \n",
      "2933  12777511.0                    9.4                  9.4   \n",
      "2934  12633897.0                    9.8                  9.9   \n",
      "2935    125525.0                    1.2                  1.3   \n",
      "2936  12366165.0                    1.6                  1.7   \n",
      "2937  12222251.0                   11.0                 11.2   \n",
      "\n",
      "      Income composition of resources  Schooling  \n",
      "0                               0.479       10.1  \n",
      "1                               0.476       10.0  \n",
      "2                               0.470        9.9  \n",
      "3                               0.463        9.8  \n",
      "4                               0.454        9.5  \n",
      "...                               ...        ...  \n",
      "2933                            0.407        9.2  \n",
      "2934                            0.418        9.5  \n",
      "2935                            0.427       10.0  \n",
      "2936                            0.427        9.8  \n",
      "2937                            0.434        9.8  \n",
      "\n",
      "[2938 rows x 22 columns]\n",
      "Index(['Country', 'Year', 'Status', 'Life expectancy ', 'Adult Mortality',\n",
      "       'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B',\n",
      "       'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure',\n",
      "       'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n",
      "       ' thinness  1-19 years', ' thinness 5-9 years',\n",
      "       'Income composition of resources', 'Schooling'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "raw_df = pd.read_csv('life_expect.csv') #salvar o dataframe na variável 'raw_df'\n",
    "print(raw_df) #mostrar o dataframe\n",
    "print(raw_df.columns) #mostrar as colunas do dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f116bea-6473-400c-9124-7212e5a40088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataset possui 2938 instâncias e 22 atributos.\n"
     ]
    }
   ],
   "source": [
    "print('O dataset possui', raw_df.shape[0], 'instâncias e', raw_df.shape[1], 'atributos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1810142-a3ae-421e-8faa-e24e269845eb",
   "metadata": {},
   "source": [
    "Nosso dataset possui dados em diferentes unidades: alguns estão em anos, porcentagem, unidade por milhar, etc. Para nos guiar a respeito da unidade utilizada em cada coluna, criei um dicionário abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b243bbd-dc46-4ed9-a282-917fafd62060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explicação de cada coluna segundo o Kaggle\n",
    "info_colunas = {\n",
    "    'Country' : {'Country'},\n",
    "    'Year' : {'Year of the data'},\n",
    "    'Status' : {'developing or developed country?'},\n",
    "    'Life expectancy ' : {'Life Expectancy in age'},\n",
    "    'Adult Mortality' : {'Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population) '},\n",
    "    'infant deaths' : {'Number of Infant Deaths per 1000 population'},\n",
    "    'Alcohol' : {'Alcohol, recorded per capita (15+) consumption (in litres of pure alcohol)'},\n",
    "    'percentage expenditure' : {'Expenditure on health as a percentage of Gross Domestic Product per capita(%) '},\n",
    "    'Hepatitis B' : {'Hepatitis B (HepB) immunization coverage among 1-year-olds (%)'},\n",
    "    'Measles ' : {'Measles - number of reported cases per 1000 population '},\n",
    "    ' BMI ' : {'Average Body Mass Index of entire population '},\n",
    "    'under-five deaths ' : {'Number of under-five deaths per 1000 population'},\n",
    "    'Polio' : {'Polio (Pol3) immunization coverage among 1-year-olds (%) '},\n",
    "    'Total expenditure' : {'General government expenditure on health as a percentage of total government expenditure (%)'},\n",
    "    'Diphtheria ' : {'Diphtheria tetanus toxoid and pertussis (DTP3) immunization coverage among 1-year-olds (%) '},\n",
    "    ' HIV/AIDS' : {'Deaths per 1 000 live births HIV/AIDS (0-4 years) '},\n",
    "    'GDP' : {'Gross Domestic Product per capita (in USD)'},\n",
    "    'Population' : {'Population of the country '},\n",
    "    ' thinness  1-19 years' : {'Prevalence of thinness among children and adolescents for Age 10 to 19 (% ) '},\n",
    "    ' thinness 5-9 years' : {'Prevalence of thinness among children for Age 5 to 9(%) '},\n",
    "    'Income composition of resources' : {'Human Development Index in terms of income composition of resources (index ranging from 0 to 1) '},\n",
    "    'Schooling' : {'Number of years of Schooling(years) '}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f75781-49ce-4958-96d9-5de11eff63f0",
   "metadata": {},
   "source": [
    "Decidimos que os dados contidos nas colunas \"Country\" e \"Year\" não serão úteis para a nossa análise, de forma que eles serão removidos do dataset. Verificamos, também, que há uma coluna contendendo dados em string a respeito do status de desenvolvimento de cada país (em que as opções possíveis são 'desenvolvido' e 'em desenvolvimento'). Aplicaremos um método de mapeamento para transformar esses valores em string em valores booleanos 0 e 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0ecda1e-7b26-4f26-ad52-dd8508079b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1_df = raw_df.drop( #armazenamos na variável 'raw_1_df' o dataframe sem as colunas 'country' e 'year'\n",
    "    [\"Country\", 'Year'], axis=1)\n",
    "#print(raw_1_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15a2cb5c-c081-4cd2-aff6-2fcac7414f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Status  Life expectancy   Adult Mortality  infant deaths  Alcohol  \\\n",
      "0          1              65.0            263.0             62     0.01   \n",
      "1          1              59.9            271.0             64     0.01   \n",
      "2          1              59.9            268.0             66     0.01   \n",
      "3          1              59.5            272.0             69     0.01   \n",
      "4          1              59.2            275.0             71     0.01   \n",
      "...      ...               ...              ...            ...      ...   \n",
      "2933       1              44.3            723.0             27     4.36   \n",
      "2934       1              44.5            715.0             26     4.06   \n",
      "2935       1              44.8             73.0             25     4.43   \n",
      "2936       1              45.3            686.0             25     1.72   \n",
      "2937       1              46.0            665.0             24     1.68   \n",
      "\n",
      "      percentage expenditure  Hepatitis B  Measles    BMI   \\\n",
      "0                  71.279624         65.0      1154   19.1   \n",
      "1                  73.523582         62.0       492   18.6   \n",
      "2                  73.219243         64.0       430   18.1   \n",
      "3                  78.184215         67.0      2787   17.6   \n",
      "4                   7.097109         68.0      3013   17.2   \n",
      "...                      ...          ...       ...    ...   \n",
      "2933                0.000000         68.0        31   27.1   \n",
      "2934                0.000000          7.0       998   26.7   \n",
      "2935                0.000000         73.0       304   26.3   \n",
      "2936                0.000000         76.0       529   25.9   \n",
      "2937                0.000000         79.0      1483   25.5   \n",
      "\n",
      "      under-five deaths   Polio  Total expenditure  Diphtheria    HIV/AIDS  \\\n",
      "0                     83    6.0               8.16         65.0        0.1   \n",
      "1                     86   58.0               8.18         62.0        0.1   \n",
      "2                     89   62.0               8.13         64.0        0.1   \n",
      "3                     93   67.0               8.52         67.0        0.1   \n",
      "4                     97   68.0               7.87         68.0        0.1   \n",
      "...                  ...    ...                ...          ...        ...   \n",
      "2933                  42   67.0               7.13         65.0       33.6   \n",
      "2934                  41    7.0               6.52         68.0       36.7   \n",
      "2935                  40   73.0               6.53         71.0       39.8   \n",
      "2936                  39   76.0               6.16         75.0       42.1   \n",
      "2937                  39   78.0               7.10         78.0       43.5   \n",
      "\n",
      "             GDP  Population   thinness  1-19 years   thinness 5-9 years  \\\n",
      "0     584.259210  33736494.0                   17.2                 17.3   \n",
      "1     612.696514    327582.0                   17.5                 17.5   \n",
      "2     631.744976  31731688.0                   17.7                 17.7   \n",
      "3     669.959000   3696958.0                   17.9                 18.0   \n",
      "4      63.537231   2978599.0                   18.2                 18.2   \n",
      "...          ...         ...                    ...                  ...   \n",
      "2933  454.366654  12777511.0                    9.4                  9.4   \n",
      "2934  453.351155  12633897.0                    9.8                  9.9   \n",
      "2935   57.348340    125525.0                    1.2                  1.3   \n",
      "2936  548.587312  12366165.0                    1.6                  1.7   \n",
      "2937  547.358878  12222251.0                   11.0                 11.2   \n",
      "\n",
      "      Income composition of resources  Schooling  \n",
      "0                               0.479       10.1  \n",
      "1                               0.476       10.0  \n",
      "2                               0.470        9.9  \n",
      "3                               0.463        9.8  \n",
      "4                               0.454        9.5  \n",
      "...                               ...        ...  \n",
      "2933                            0.407        9.2  \n",
      "2934                            0.418        9.5  \n",
      "2935                            0.427       10.0  \n",
      "2936                            0.427        9.8  \n",
      "2937                            0.434        9.8  \n",
      "\n",
      "[2938 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "#define um dicionário que determina pelo que cada valor deve ser substituido na série\n",
    "mapear_status = {'Developing' : 1, 'Developed' : 0} \n",
    "\n",
    "#cria uma copia do df onde será realizada a iteração\n",
    "raw_copy_df = raw_1_df.copy()\n",
    "#print(raw_copy_df.copy)\n",
    "\n",
    "#Realiza o mapeamento\n",
    "raw_1_df['Status'] = raw_copy_df['Status'].map(mapear_status, na_action=None)\n",
    "\n",
    "print(raw_1_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a89e60e-b839-4ec7-86d0-3c74ad7ca338",
   "metadata": {},
   "source": [
    "Pronto! Agora que nosso dataframe possui apenas as colunas que utilizaremos para a nossa predição e todos os dados estão em formato número, podemos prosseguir com o tratamento dos dados. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0de0c2b-7e72-4d9e-99c2-2f1fcf8c8cdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dados NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc80edca-26f1-4efc-8afb-f2eca8460c94",
   "metadata": {},
   "source": [
    "No tratamendo de Dados, existem diferentes formas de se lidar com dados NaN. Aqui, iremos comparar 3 métodos diferentes: <br>\n",
    "\n",
    "1. Preencher os dados NaN com a mediana <br>\n",
    "2. Excluir todas as linhas contendo pelo menos um dado NaN <br>\n",
    "3. Excluir colunas com grande volume de dados NaN e só então excluir as linhas contendo pelo menos um dado NaN <br>\n",
    "<br>\n",
    "Entendemos que essas não são as únicas formas possíveis de se tratar dados NaN, sendo possível até mesmo unir as técnicas acima. No entanto, elencamos 3 opções a fim de compará-las e determinar a melhor estratégia para o nosso conjunto de dados. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a22ab39-890f-4d69-9eb3-783eac7af207",
   "metadata": {},
   "source": [
    "Primeiro, vamos iniciar utilizando o método `.info()` para saber se o nosso dataset possui dados NaN e se há colunas específicas com um maior número de dados NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "406de5e9-7713-47dc-a613-40655e13aac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2938 entries, 0 to 2937\n",
      "Data columns (total 20 columns):\n",
      " #   Column                           Non-Null Count  Dtype  \n",
      "---  ------                           --------------  -----  \n",
      " 0   Status                           2938 non-null   int64  \n",
      " 1   Life expectancy                  2928 non-null   float64\n",
      " 2   Adult Mortality                  2928 non-null   float64\n",
      " 3   infant deaths                    2938 non-null   int64  \n",
      " 4   Alcohol                          2744 non-null   float64\n",
      " 5   percentage expenditure           2938 non-null   float64\n",
      " 6   Hepatitis B                      2385 non-null   float64\n",
      " 7   Measles                          2938 non-null   int64  \n",
      " 8    BMI                             2904 non-null   float64\n",
      " 9   under-five deaths                2938 non-null   int64  \n",
      " 10  Polio                            2919 non-null   float64\n",
      " 11  Total expenditure                2712 non-null   float64\n",
      " 12  Diphtheria                       2919 non-null   float64\n",
      " 13   HIV/AIDS                        2938 non-null   float64\n",
      " 14  GDP                              2490 non-null   float64\n",
      " 15  Population                       2286 non-null   float64\n",
      " 16   thinness  1-19 years            2904 non-null   float64\n",
      " 17   thinness 5-9 years              2904 non-null   float64\n",
      " 18  Income composition of resources  2771 non-null   float64\n",
      " 19  Schooling                        2775 non-null   float64\n",
      "dtypes: float64(16), int64(4)\n",
      "memory usage: 459.2 KB\n"
     ]
    }
   ],
   "source": [
    "raw_1_df.info() #Obtém informações quanto ao número de valores não nulos no dataframe original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fdc7c6-3a43-4538-adc4-d512b3ea290e",
   "metadata": {},
   "source": [
    "Observamos que as colunas 'Alcohol', 'Life expectancy', 'Adult Mortality', 'Hepatitis B', 'BMI', 'Polio', 'Total expenditure', 'Diphtheria', 'GDP', 'Population', 'thinness  1-19 years','thinness 5-9 years','Income composition of resources' e 'Schooling' possuem dados NaN, sendo as colunas `Population`, `GDP` e `Hepatites B` aquelas com o maior número de dados NaN. <br>\n",
    "A partir do dataset original, vamos criar 3 novos datasets, cada um utilizando um dos métodos de se lidar com dados NaN mencionados acima. Os datasets serão nomeados a partir das letras gregas alpha, beta e gamma e serão futuramente comparados a fim de verificar qual leva a uma melhor acurácia na predição.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a11dc0-a72c-4f12-8d5a-d6da594b3cfe",
   "metadata": {},
   "source": [
    "## Método 1: Remover todas as linhas contendo dados NaN (Alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75cd484f-1533-42ed-a331-5625d27fe994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após remover as linhas com dados faltantes, obtivemos um dataset com 1649 instâncias e 20 atributos.\n"
     ]
    }
   ],
   "source": [
    "alpha_df = raw_1_df.dropna() #armazenamos na variável 'alpha_df' o dataframe sem as linhas com valores NaN\n",
    "#print(alpha_df)\n",
    "print('Após remover as linhas com dados faltantes, obtivemos um dataset com', \n",
    "      alpha_df.shape[0], 'instâncias e', alpha_df.shape[1], 'atributos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8f3296-69bd-4874-97ea-56e77cd211e7",
   "metadata": {},
   "source": [
    "## Método 2: Preencher linhas contendo dados NaN utilizando a mediana (Beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be5079a-f92b-4027-a6c9-0fa96c033954",
   "metadata": {},
   "source": [
    "Para preencher as linhas contendo dados NaN utilizaremos o método `Simple Imputer` do Sklearn e a estratégia de preenchimento `mediana`. Como temos uma coluna de dados booleanos 0 e 1 ('Status'), não podemos utilizar essa estratégia sobre esses dados, afinal seria imputado um valor entre 0 e 1! Nesse caso, teríamos que aplicar a estratégia `mode` nessa coluna. No entanto, nossa coluna 'Status' não possui nenhum dado NaN, de forma que não seja necessário usar nenhum método de imputamento sobre ela. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "568e998f-ae2a-4a79-810e-b0e105633662",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_df = raw_1_df #criamos uma cópia do dataset original\n",
    "\n",
    "#Definir em quais colunas desejamos preencher os dados NaN faltantes\n",
    "colunas = ['Adult Mortality', 'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B',\n",
    "       'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure',\n",
    "       'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n",
    "       ' thinness  1-19 years', ' thinness 5-9 years',\n",
    "       'Income composition of resources', 'Schooling']\n",
    "\n",
    "#Define o método de imputamento e a estratégia\n",
    "imputer = SimpleImputer(missing_values = np.nan, \n",
    "                        strategy ='mean')\n",
    "\n",
    "#Fita os dados sobre as colunas que desejamos imputar\n",
    "imputer = imputer.fit(raw_1_df[colunas])\n",
    "\n",
    "#Cria um novo dataset com as colunas preenchidas pela mediana!\n",
    "beta_df[colunas] = imputer.transform(raw_1_df[colunas])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dd22c83-2731-4e67-9a23-6a976b00f84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(beta_df)\n",
    "#beta_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6360335-b765-44dd-911a-c7cf9bbf93b5",
   "metadata": {},
   "source": [
    "## Método 3: Excluir colunas com grande volume de dados NaN (Gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12af6c1-10bd-41bd-aeee-fc07f4f64143",
   "metadata": {},
   "source": [
    "Por fim, iremos criar um terceiro dataset a partir de uma técnica onde identificamos colunas com um grande número de valores NaN e as removemos. Só então removemos as linhas contendo pelo menos um dado NaN. Para isso, iremos remover as colunas `Hepatitis B, Population e GDP`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e328b4f6-10cb-43a3-afd2-4f65d36cd29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Após remover as linhas com dados faltantes, obtivemos um dataset com 2928 instâncias e 17 atributos.\n"
     ]
    }
   ],
   "source": [
    "#armazenamos na variável 'df_semcolunas_nan' o dataframe sem as colunas com muitos valores nan e as colunas país e ano\n",
    "df_semcolunas_nan = raw_1_df.drop(\n",
    "    ['Hepatitis B', 'Population', 'GDP'], axis=1)\n",
    "#print(df_semcolunas_nan)\n",
    "\n",
    "\n",
    "#armazenamos na variável 'final_df_semcolunas_nan' o dataframe sem as linhas com valores NaN\n",
    "gamma_df = df_semcolunas_nan.dropna()\n",
    "print('Após remover as linhas com dados faltantes, obtivemos um dataset com', \n",
    "      gamma_df.shape[0], 'instâncias e', gamma_df.shape[1], 'atributos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c46518-8519-41f4-985f-b7b563f8fff2",
   "metadata": {},
   "source": [
    "Mas e se essas colunas que removemos forem essenciais para a predição do nosso target? Para verificar se esse é o caso, podemos utilizar o método SHAP, que verifica o grau de importância de cada atributo na predição. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02509636-eb1e-457e-a842-f0f2501b3b1b",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d710117-bb48-4e90-a10f-3b3a4e14b24a",
   "metadata": {},
   "source": [
    "Aplicar o SHAP, plotar a tabelinha. Tudo indica que vai mostrar que esses três atributos não influenciam tanto no target, já que quando fizemos isso em Dados 2 teve uma melhora na performance sem essas colunas (então elas provavelmente não eram tão importantes assim). É só fazer o gráfico e colocar um parágrafo falando \"com isso sabemos que essas colunas não são tão essenciais para a predição, de forma que podemos removê-las a fim de verificar se há uma melhora na performance\" ou algo desse tipo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba614e2-a902-4010-8380-b19a4cc2dac3",
   "metadata": {},
   "source": [
    "Pronto, agora temos 3 datasets criados a partir de diferentes métodos de tratamento de dados NaN! Cada um desses Datasets possui 0 valores NaN, deixando-os prontos para a próxima fase do tratamento de dados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ce72957-17df-46fd-93f3-61e29580b5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(alpha_df)\n",
    "#print(beta_df)\n",
    "#print(gamma_df)\n",
    "#alpha_df.info()\n",
    "#beta_df.info()\n",
    "#gamma_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323b3783-6d0e-4120-8272-07504f5889fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949f76a9-3382-4fa2-8c0d-a213d68c7e5e",
   "metadata": {},
   "source": [
    "Utilizaremos 3 modelos de Machine Learning com os nossos dados: KNN-Vizinhos, Árvore de Decisão e Floresta de Decisão. Modelos KNN realizam sua previsão com base na distância entre os dados, de forma que colunas contendo dados com dimensões muito maiores que as outras podem apresentar um peso maior na decisão que não se reflete na realidade do problema. Por isso, é recomendável realizar uma normalização dos dados antes de prosseguir. <br>\n",
    "\n",
    "Para verificar a influência da normalização (ou a falta dela) nos dados, iremos comparar também a eficiência dos nossos modelos. Espera-se que seja percebida alguma diferença na predição com o modelo KNN e nenhuma (ou pouca, dada a aleatoriedade inerente a esses modelos) diferença para os modelos árvore e floresta de decisão. <br>\n",
    "\n",
    "Optamos por comparar criar duas versões para cada um dos datasets já criados anteriormente: <br>\n",
    "\n",
    "a. Versão sem normalizar <br>\n",
    "b. Versão utilizando Normalização Padrão <br> \n",
    "\n",
    "Assim teremos 6 datasets finais:\n",
    "\n",
    "1. alpha_df\n",
    "2. alpha_norm_df\n",
    "3. beta_df\n",
    "4. beta_norm_df\n",
    "5. gamma_df\n",
    "6. gamma_norm_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bf987293-2c9b-4a31-8f91-ee448d994133",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iasodara23005\\AppData\\Local\\Temp\\ipykernel_776\\1795983486.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  norm_alpha_df[Colunas] = normalizador.transform(alpha_df[Colunas])\n",
      "C:\\Users\\iasodara23005\\AppData\\Local\\Temp\\ipykernel_776\\1795983486.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  norm_gamma_df[Colunas_gamma] = normalizador.transform(gamma_df[Colunas_gamma])\n"
     ]
    }
   ],
   "source": [
    "#Lista com as colunas onde será realizada a normalização.\n",
    "Colunas = ['Adult Mortality',\n",
    "       'infant deaths', 'Alcohol', 'percentage expenditure', 'Hepatitis B',\n",
    "       'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure',\n",
    "       'Diphtheria ', ' HIV/AIDS', 'GDP', 'Population',\n",
    "       ' thinness  1-19 years', ' thinness 5-9 years',\n",
    "       'Income composition of resources', 'Schooling']\n",
    "\n",
    "#Como o dataframe gamma possui menos colunas que as outras, criamos uma lista separada\n",
    "Colunas_gamma = ['Adult Mortality',\n",
    "       'infant deaths', 'Alcohol', 'percentage expenditure',\n",
    "       'Measles ', ' BMI ', 'under-five deaths ', 'Polio', 'Total expenditure',\n",
    "       'Diphtheria ', ' HIV/AIDS',\n",
    "       ' thinness  1-19 years', ' thinness 5-9 years',\n",
    "       'Income composition of resources', 'Schooling']\n",
    "\n",
    "#Cria cópias de cada um dos 3 datasets\n",
    "norm_alpha_df = alpha_df\n",
    "norm_beta_df = beta_df\n",
    "norm_gamma_df = gamma_df\n",
    "\n",
    "#Define o método de normalização que será utilizado\n",
    "normalizador = StandardScaler()\n",
    "\n",
    "#Fita os dados das colunas desejadas \n",
    "#Realiza a normalização sobre os dados Alpha\n",
    "normalizador.fit(alpha_df[Colunas])\n",
    "norm_alpha_df[Colunas] = normalizador.transform(alpha_df[Colunas])\n",
    "\n",
    "#Fita os dados das colunas desejadas \n",
    "#Realiza a normalização sobre os dados Beta\n",
    "normalizador.fit(beta_df[Colunas])\n",
    "norm_beta_df[Colunas] = normalizador.transform(beta_df[Colunas])\n",
    "\n",
    "#Fita os dados das colunas desejadas \n",
    "#Realiza a normalização sobre os dados Gamma\n",
    "normalizador.fit(gamma_df[Colunas_gamma])\n",
    "norm_gamma_df[Colunas_gamma] = normalizador.transform(gamma_df[Colunas_gamma])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97acc44e-71e8-4d40-b8bc-63a5d925c77f",
   "metadata": {},
   "source": [
    "Pronto, agora nossos dados estão todos normalizados, tratados e prontos para seguir para o próximo passo!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b86d21-4588-4f4b-81a7-93c4505e9059",
   "metadata": {},
   "source": [
    "# Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc87680-1241-404b-bb72-dd235c7b51d6",
   "metadata": {},
   "source": [
    "1. Como preencher dados NaN com o SimpleImputer: https://medium.com/data-hackers/tratamento-e-transforma%C3%A7%C3%A3o-de-dados-nan-uma-vis%C3%A3o-geral-e-pr%C3%A1tica-54efa9fc7a98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff9035-2315-4474-8ada-7cabfa62e1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
